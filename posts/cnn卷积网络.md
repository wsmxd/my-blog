---
title: "cnn卷积流程"
date: "2025-12-19"
description: "卷积神经网络完整工作流程图解"
tags: [python, cnn]
cover: "cnn.png"
category: "professional"
---

# 卷积神经网络完整工作流程图解

## 一、卷积核在多通道上的工作方式（核心图解）

### 1. **输入→单个输出通道的完整过程**
```
输入图像：3个通道（RGB），每个5×5
卷积核组：生成1个输出通道需要3个卷积核（每个输入通道1个）

输入张量 (3×5×5)         卷积核组 (3×3×3)         输出 (1×3×3)
┌─────────────┐         ┌─────────────────┐       ┌───────┐
│ R通道 5×5   │         │ R通道核 3×3    │       │   O₁₁ │
├─────────────┤         ├─────────────────┤       │   O₁₂ │
│ G通道 5×5   │   *     │ G通道核 3×3    │   =   │   O₁₃ │
├─────────────┤         ├─────────────────┤       └───────┘
│ B通道 5×5   │         │ B通道核 3×3    │
└─────────────┘         └─────────────────┘

计算过程：
对于输出位置(i,j)：
O(i,j) = ∑_{c=1}^{3} [R_c与对应卷积核的卷积结果]
       = R通道卷积 + G通道卷积 + B通道卷积 + 偏置
```

### 2. **生成N个输出通道的图解**
```
输入：C_in个通道
输出：C_out=N个通道
卷积核：需要N组，每组C_in个核

输入 [C_in×H×W]    卷积核 [N×C_in×K_h×K_w]    输出 [N×H_out×W_out]
    │                     │                          │
    └─┬─┬─┬─┬─┬─┐         └─┬─┬─┬─┬─┬─┐              └─┬─┬─┬─┬─┬─┐
      │ │ │...│ │           │ │ │...│ │                │ │ │...│ │
      1 2 3  C_in           1 2 3  C_in                1 2 3  N

每个输出通道的生成过程：
输出通道1 = 第1组卷积核工作结果
   ┌───────────────┐
   │ 核1_1 × 输入通道1 │→+
   │ 核1_2 × 输入通道2 │→ 相加 → 输出通道1
   │ ...             │→+
   │ 核1_C × 输入通道C_in│
   └───────────────┘

输出通道2 = 第2组卷积核工作结果
   ┌───────────────┐
   │ 核2_1 × 输入通道1 │→+
   │ 核2_2 × 输入通道2 │→ 相加 → 输出通道2
   │ ...             │→+
   │ 核2_C × 输入通道C_in│
   └───────────────┘

... 重复N次 ...

输出通道N = 第N组卷积核工作结果
   ┌───────────────┐
   │ 核N_1 × 输入通道1 │→+
   │ 核N_2 × 输入通道2 │→ 相加 → 输出通道N
   │ ...             │→+
   │ 核N_C × 输入通道C_in│
   └───────────────┘
```

## 二、详细数字示例：3输入通道 → 2输出通道

### 示例数据：
```
输入图像：3×3×3（3个3×3的通道）
卷积核：2组，每组3个2×2的核
步长=1，填充=0

输入通道1（R）：    输入通道2（G）：    输入通道3（B）：
┌───────┐         ┌───────┐         ┌───────┐
│ 1 2 1 │         │ 0 1 0 │         │ 2 1 2 │
│ 0 1 1 │         │ 1 0 1 │         │ 1 0 1 │
│ 2 1 0 │         │ 0 1 0 │         │ 0 2 0 │
└───────┘         └───────┘         └───────┘

卷积核（第1组，用于输出通道1）：
核1_1（对R通道）：  核1_2（对G通道）：  核1_3（对B通道）：
┌─────┐           ┌─────┐           ┌─────┐
│ 1 0 │           │ 0 1 │           │-1 0 │
│ 0 1 │           │ 1 0 │           │ 0 1 │
└─────┘           └─────┘           └─────┘

卷积核（第2组，用于输出通道2）：
核2_1（对R通道）：  核2_2（对G通道）：  核2_3（对B通道）：
┌─────┐           ┌─────┐           ┌─────┐
│ 0 1 │           │ 1 0 │           │ 0 -1│
│-1 0 │           │ 0 1 │           │ 1 0 │
└─────┘           └─────┘           └─────┘
偏置：b1=0.1, b2=-0.1
```

### 计算输出通道1的第一个值(0,0位置)：
```
1. R通道贡献：
   输入区域(0:2,0:2) = [1,2]  卷积核1_1 = [1,0]
                       [0,1]              [0,1]
   计算：1×1 + 2×0 + 0×0 + 1×1 = 1+0+0+1 = 2

2. G通道贡献：
   输入区域(0:2,0:2) = [0,1]  卷积核1_2 = [0,1]
                       [1,0]              [1,0]
   计算：0×0 + 1×1 + 1×1 + 0×0 = 0+1+1+0 = 2

3. B通道贡献：
   输入区域(0:2,0:2) = [2,1]  卷积核1_3 = [-1,0]
                       [1,0]              [0,1]
   计算：2×(-1) + 1×0 + 1×0 + 0×1 = -2+0+0+0 = -2

4. 总和加偏置：
   输出1(0,0) = 2 + 2 + (-2) + 0.1 = 2.1
```

### 计算输出通道2的第一个值(0,0位置)：
```
使用第2组卷积核：
1. R通道贡献：1×0 + 2×1 + 0×(-1) + 1×0 = 0+2+0+0 = 2
2. G通道贡献：0×1 + 1×0 + 1×0 + 0×1 = 0+0+0+0 = 0
3. B通道贡献：2×0 + 1×(-1) + 1×1 + 0×0 = 0-1+1+0 = 0
4. 总和加偏置：2 + 0 + 0 + (-0.1) = 1.9
```

### 最终输出：
```
输出通道1（2×2）：    输出通道2（2×2）：
┌───────┐           ┌───────┐
│ 2.1  ? │           │ 1.9  ? │
│   ?  ? │           │   ?  ? │
└───────┘           └───────┘
```

## 三、尺寸计算公式详解

### 1. **输出尺寸公式推导**
```
输入尺寸：H_in × W_in × C_in
卷积核：K_h × K_w
步长：S
填充：P
输出通道数：C_out

输出高度 H_out = ⌊(H_in + 2P - K_h) / S⌋ + 1
输出宽度 W_out = ⌊(W_in + 2P - K_w) / S⌋ + 1
输出通道数 C_out = 设置的输出通道数

输出张量形状：[C_out × H_out × W_out]
```

### 2. **公式可视化推导**
```
输入高度H_in=5，卷积核K=3，步长S=2，填充P=1

步骤1：添加填充
原始：■■■■■
填充后：□■■■■■□  (两边各加1个填充)

步骤2：计算可放置卷积核的位置
卷积核覆盖范围：3个位置
第一个位置：□■■
第二个位置：  ■■■
第三个位置：   ■■■
第四个位置：    ■■■□

步骤3：应用公式
H_out = (5 + 2×1 - 3)/2 + 1 = (5+2-3)/2 + 1 = 4/2 + 1 = 2 + 1 = 3
实际位置数：位置1、3、5 → 3个位置 ✓
```

### 3. **尺寸计算流程图**
```
开始
   ↓
输入尺寸：[C_in, H_in, W_in]
   ↓
选择：卷积核大小K，步长S，填充P，输出通道C_out
   ↓
计算：H_out = (H_in + 2P - K)/S + 1
计算：W_out = (W_in + 2P - K)/S + 1
   ↓
输出尺寸：[C_out, H_out, W_out]
   ↓
计算参数数量：Params = (K×K×C_in + 1) × C_out
   ↓
结束
```

## 四、池化操作详细图解

### 1. **最大池化工作流程**
```
输入特征图 (4×4)：                    最大池化 (2×2, 步长2)：
位置标记：                           滑动窗口过程：
┌───────────────┐                  窗口1(红色)   窗口2(蓝色)
│ (0,0) (0,1)│(0,2) (0,3)│        ┌──────┬──────┐
│   1     3  │  2     4  │        │ MAX  │ MAX  │
│ (1,0) (1,1)│(1,2) (1,3)│        │(1,3,4,2)│(2,4,1,3)│
│   4     2  │  1     3  │        │  →4  │  →4  │
├───────────────┤        ├──────┼──────┤
│ (2,0) (2,1)│(2,2) (2,3)│        │ MAX  │ MAX  │
│   2     4  │  3     1  │        │(2,4,3,1)│(3,1,4,2)│
│ (3,0) (3,1)│(3,2) (3,3)│        │  →4  │  →4  │
│   3     1  │  4     2  │        └──────┴──────┘
└───────────────┘

详细计算：
窗口1：位置[(0,0),(0,1),(1,0),(1,1)] = [1,3,4,2] → max=4
窗口2：位置[(0,2),(0,3),(1,2),(1,3)] = [2,4,1,3] → max=4
窗口3：位置[(2,0),(2,1),(3,0),(3,1)] = [2,4,3,1] → max=4
窗口4：位置[(2,2),(2,3),(3,2),(3,3)] = [3,1,4,2] → max=4

输出 (2×2)：[4, 4]
           [4, 4]
```

### 2. **池化尺寸计算示例**
```
输入：6×6特征图
池化窗口：3×3
步长：2
填充：0

图形化计算：
输入网格：6×6 = 36个位置
池化窗口：3×3覆盖

滑动过程：
第一次：覆盖(0:3, 0:3)
第二次：向右移动2步，覆盖(0:3, 2:5)
第三次：向右移动2步，覆盖(0:3, 4:7)但只有6列→停止

换行：
第四次：向下移动2步，覆盖(2:5, 0:3)
第五次：覆盖(2:5, 2:5)
第六次：覆盖(2:5, 4:7)→停止

公式计算：
H_out = (6 - 3)/2 + 1 = 3/2 + 1 = 1.5 + 1 = 2.5 → 向下取整=2
W_out = (6 - 3)/2 + 1 = 3/2 + 1 = 1.5 + 1 = 2.5 → 向下取整=2
输出：2×2

实际有效位置：4个窗口 ✓
```

## 五、完整CNN示例：从输入到输出

### 1. **LeNet-5风格网络尺寸变化**
```
输入：[1, 1, 32, 32]  # 批量1，通道1，32×32 MNIST图像
     ↓
卷积层1：C_out=6, K=5, S=1, P=0
公式：H_out = (32 + 0 - 5)/1 + 1 = 28
输出：[1, 6, 28, 28]
     ↓
池化层1：K=2, S=2, P=0
公式：H_out = (28 - 2)/2 + 1 = 13 + 1 = 14? 等等，重新计算：
正确：(28 - 2)/2 + 1 = 26/2 + 1 = 13 + 1 = 14 ✓
输出：[1, 6, 14, 14]
     ↓
卷积层2：C_out=16, K=5, S=1, P=0
公式：H_out = (14 + 0 - 5)/1 + 1 = 10
输出：[1, 16, 10, 10]
     ↓
池化层2：K=2, S=2, P=0
公式：H_out = (10 - 2)/2 + 1 = 8/2 + 1 = 4 + 1 = 5
输出：[1, 16, 5, 5]
     ↓
展平：16×5×5 = 400
全连接层1：120个神经元
全连接层2：84个神经元
输出层：10个类别（数字0-9）
```

### 2. **参数数量计算**
```
卷积层1：输入1通道，输出6通道，5×5卷积核
参数 = (5×5×1 + 1) × 6 = (25 + 1) × 6 = 156

卷积层2：输入6通道，输出16通道，5×5卷积核
参数 = (5×5×6 + 1) × 16 = (150 + 1) × 16 = 2416

全连接层1：400 → 120
参数 = (400 + 1) × 120 = 48120

全连接层2：120 → 84
参数 = (120 + 1) × 84 = 10164

输出层：84 → 10
参数 = (84 + 1) × 10 = 850

总参数：156 + 2416 + 48120 + 10164 + 850 = 61,706
```

## 六、特殊卷积操作

### 1. **1×1卷积（通道混合）**
```
输入：[C_in, H, W]
1×1卷积：[C_out, C_in, 1, 1]

工作方式：在每个空间位置独立进行
对于位置(i,j):
输出(c_out,i,j) = ∑_{c_in=1}^{C_in} w(c_out, c_in) × 输入(c_in, i,j) + 偏置

相当于全连接层应用于每个位置，混合通道信息但不改变空间尺寸。
```

### 2. **空洞卷积（Dilated Convolution）**
```
普通卷积：核元素连续
空洞卷积：核元素间有间隔

输入：■■■■■■■■
普通3×3卷积：覆盖连续3个位置
空洞卷积（膨胀率2）：覆盖位置0、2、4

尺寸公式：
H_out = ⌊(H_in + 2P - dilation×(K-1) - 1)/S⌋ + 1
```

### 3. **分组卷积（Group Convolution）**
```
输入C_in通道分成G组
每组独立处理C_in/G输入通道，产生C_out/G输出通道
最后拼接所有组的输出

参数减少为原来的1/G
```

## 七、总结表格

| 操作 | 输入形状 | 参数 | 输出形状公式 | 示例 |
|------|---------|------|-------------|------|
| 卷积 | [C_in,H,W] | (K²×C_in+1)×C_out | H_out=⌊(H+2P-K)/S⌋+1 | 输入[3,32,32], K=3,S=1,P=1→[64,32,32] |
| 池化 | [C,H,W] | 0 | H_out=⌊(H+2P-K)/S⌋+1 | 输入[64,32,32], K=2,S=2→[64,16,16] |
| 1×1卷积 | [C_in,H,W] | (1×1×C_in+1)×C_out | [C_out,H,W] | 改变通道数，保持空间尺寸 |
| 展平 | [C,H,W] | - | [C×H×W] | [64,7,7]→[3136] |

这个图解展示了卷积核如何在多个输入通道上工作，通过N组卷积核生成N个输出通道，以及相关的尺寸计算公式。理解这个过程是掌握CNN工作原理的关键！